{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/htttx7197fv90v3w5v6m_s_c0000gn/T/ipykernel_75439/1596269529.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "from tools.html_processor import HTMLProcessor\n",
    "from tools.prompt_templator import PromptTemplator\n",
    "from tools.llm_invocator import LLMInvocator\n",
    "from tools.stealth_scraper import StealthScraper\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "stealth_scraper = StealthScraper()\n",
    "html_processor = HTMLProcessor()\n",
    "prompt_templator = PromptTemplator()\n",
    "llm_invocator = LLMInvocator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"01_llmpipeline/specbook.csv\")\n",
    "df['id'] = range(1, len(df) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-05 23:28:36 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:36 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:36 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:36 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:36 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:36 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:36 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (224015 chars)\n",
      "2025-07-05 23:28:36 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:36 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (115442 chars)\n",
      "2025-07-05 23:28:36 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (114667 chars)\n",
      "2025-07-05 23:28:36 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (228738 chars)\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (11333 chars)\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (11339 chars)\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (11333 chars)\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (11339 chars)\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (427237 chars)\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (11357 chars)\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (11477 chars)\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (11437 chars)\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (11399 chars)\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (610860 chars)\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (11375 chars)\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (582249 chars)\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 2/3 after 1.6s delay\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 2/3 after 2.1s delay\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (108409 chars)\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (343002 chars)\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 2/3 after 2.4s delay\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 2/3 after 1.7s delay\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (146650 chars)\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (582205 chars)\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (582249 chars)\n",
      "2025-07-05 23:28:37 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:38 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (227835 chars)\n",
      "2025-07-05 23:28:38 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (227835 chars)\n",
      "2025-07-05 23:28:38 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:38 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (227835 chars)\n",
      "2025-07-05 23:28:38 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (347408 chars)\n",
      "2025-07-05 23:28:38 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:38 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (145734 chars)\n",
      "2025-07-05 23:28:38 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (190304 chars)\n",
      "2025-07-05 23:28:38 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:38 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (717933 chars)\n",
      "2025-07-05 23:28:38 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (889591 chars)\n",
      "2025-07-05 23:28:39 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (888272 chars)\n",
      "2025-07-05 23:28:39 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (909563 chars)\n",
      "2025-07-05 23:28:39 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:39 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (922303 chars)\n",
      "2025-07-05 23:28:39 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 2/3 after 2.1s delay\n",
      "2025-07-05 23:28:39 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 2/3 after 1.8s delay\n",
      "2025-07-05 23:28:39 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (1016512 chars)\n",
      "2025-07-05 23:28:39 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (340801 chars)\n",
      "2025-07-05 23:28:39 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:39 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (976299 chars)\n",
      "2025-07-05 23:28:39 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 2/3 after 2.6s delay\n",
      "2025-07-05 23:28:39 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:39 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (685543 chars)\n",
      "2025-07-05 23:28:39 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 2/3 after 2.3s delay\n",
      "2025-07-05 23:28:39 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 3/3 after 1.1s delay\n",
      "2025-07-05 23:28:39 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 3/3 after 1.8s delay\n",
      "2025-07-05 23:28:39 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (648375 chars)\n",
      "2025-07-05 23:28:39 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (728414 chars)\n",
      "2025-07-05 23:28:39 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (180523 chars)\n",
      "2025-07-05 23:28:39 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:39 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (185646 chars)\n",
      "2025-07-05 23:28:40 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (575060 chars)\n",
      "2025-07-05 23:28:40 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:40 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (471212 chars)\n",
      "2025-07-05 23:28:40 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:40 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (429530 chars)\n",
      "2025-07-05 23:28:40 - StealthScraper - INFO - [stealth_scraper.py:276] - Requests failed, trying Firecrawl...\n",
      "2025-07-05 23:28:40 - StealthScraper - INFO - [stealth_scraper.py:586] - Scraping https://www.deltafaucet.com/kitchen/product/9159-AR-DST with Firecrawl\n",
      "2025-07-05 23:28:40 - StealthScraper - INFO - [stealth_scraper.py:588] - Acquired rate limit for https://www.deltafaucet.com/kitchen/product/9159-AR-DST\n",
      "2025-07-05 23:28:40 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:40 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (129876 chars)\n",
      "2025-07-05 23:28:41 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 3/3 after 1.9s delay\n",
      "2025-07-05 23:28:41 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 3/3 after 2.9s delay\n",
      "2025-07-05 23:28:41 - StealthScraper - INFO - [stealth_scraper.py:276] - Requests failed, trying Firecrawl...\n",
      "2025-07-05 23:28:41 - StealthScraper - INFO - [stealth_scraper.py:586] - Scraping https://www.deltafaucet.com/kitchen/product/9659-DST.html with Firecrawl\n",
      "2025-07-05 23:28:41 - StealthScraper - INFO - [stealth_scraper.py:588] - Acquired rate limit for https://www.deltafaucet.com/kitchen/product/9659-DST.html\n",
      "2025-07-05 23:28:41 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:41 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (475176 chars)\n",
      "2025-07-05 23:28:41 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 3/3 after 2.8s delay\n",
      "2025-07-05 23:28:41 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (236453 chars)\n",
      "2025-07-05 23:28:41 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 3/3 after 2.5s delay\n",
      "2025-07-05 23:28:42 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (92049 chars)\n",
      "2025-07-05 23:28:42 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 2/3 after 1.6s delay\n",
      "2025-07-05 23:28:42 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (158227 chars)\n",
      "2025-07-05 23:28:42 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (692647 chars)\n",
      "2025-07-05 23:28:42 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (683275 chars)\n",
      "2025-07-05 23:28:42 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 2/3 after 1.9s delay\n",
      "2025-07-05 23:28:42 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 2/3 after 2.8s delay\n",
      "2025-07-05 23:28:42 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (692273 chars)\n",
      "2025-07-05 23:28:42 - StealthScraper - WARNING - [stealth_scraper.py:336] - HTTP 403 error\n",
      "2025-07-05 23:28:42 - StealthScraper - INFO - [stealth_scraper.py:276] - Requests failed, trying Firecrawl...\n",
      "2025-07-05 23:28:42 - StealthScraper - INFO - [stealth_scraper.py:586] - Scraping https://www.potterybarn.com/products/moritz-round-mirror/?catalogId=84&sku=5705623&cm_ven=PLA&cm_cat=Google&cm_pla=Bath%20%3E%20Mirrors&region_id=792000&cm_ite=5705623&gclid=CjwKCAjw1uiEBhBzEiwAO9B_HZ2_K_j4vByLB9LG5R7Wzjl5-7CvVK2uO_EUyZ14R4qGoFl7nelQ-hoCCDcQAvD_BwE with Firecrawl\n",
      "2025-07-05 23:28:42 - StealthScraper - INFO - [stealth_scraper.py:588] - Acquired rate limit for https://www.potterybarn.com/products/moritz-round-mirror/?catalogId=84&sku=5705623&cm_ven=PLA&cm_cat=Google&cm_pla=Bath%20%3E%20Mirrors&region_id=792000&cm_ite=5705623&gclid=CjwKCAjw1uiEBhBzEiwAO9B_HZ2_K_j4vByLB9LG5R7Wzjl5-7CvVK2uO_EUyZ14R4qGoFl7nelQ-hoCCDcQAvD_BwE\n",
      "2025-07-05 23:28:42 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (685464 chars)\n",
      "2025-07-05 23:28:42 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (1157390 chars)\n",
      "2025-07-05 23:28:43 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (1109476 chars)\n",
      "2025-07-05 23:28:43 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:43 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (1404020 chars)\n",
      "2025-07-05 23:28:43 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:43 - StealthScraper - INFO - [stealth_scraper.py:276] - Requests failed, trying Firecrawl...\n",
      "2025-07-05 23:28:43 - StealthScraper - INFO - [stealth_scraper.py:586] - Scraping https://www.deltafaucet.com/bathroom/product/T14259-SS with Firecrawl\n",
      "2025-07-05 23:28:43 - StealthScraper - INFO - [stealth_scraper.py:588] - Acquired rate limit for https://www.deltafaucet.com/bathroom/product/T14259-SS\n",
      "2025-07-05 23:28:43 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (597913 chars)\n",
      "2025-07-05 23:28:43 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:43 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (322060 chars)\n",
      "2025-07-05 23:28:43 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (330824 chars)\n",
      "2025-07-05 23:28:43 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:43 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (318232 chars)\n",
      "2025-07-05 23:28:43 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 3/3 after 2.0s delay\n",
      "2025-07-05 23:28:43 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (335186 chars)\n",
      "2025-07-05 23:28:44 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 3/3 after 1.7s delay\n",
      "2025-07-05 23:28:44 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (317281 chars)\n",
      "2025-07-05 23:28:44 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:44 - StealthScraper - INFO - [stealth_scraper.py:276] - Requests failed, trying Firecrawl...\n",
      "2025-07-05 23:28:44 - StealthScraper - INFO - [stealth_scraper.py:586] - Scraping https://www.deltafaucet.com/bathroom/product/559LF-SSLPU with Firecrawl\n",
      "2025-07-05 23:28:44 - StealthScraper - INFO - [stealth_scraper.py:588] - Acquired rate limit for https://www.deltafaucet.com/bathroom/product/559LF-SSLPU\n",
      "2025-07-05 23:28:44 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:44 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (332826 chars)\n",
      "2025-07-05 23:28:44 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (139584 chars)\n",
      "2025-07-05 23:28:44 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:44 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (137178 chars)\n",
      "2025-07-05 23:28:44 - StealthScraper - INFO - [stealth_scraper.py:276] - Requests failed, trying Firecrawl...\n",
      "2025-07-05 23:28:44 - StealthScraper - INFO - [stealth_scraper.py:586] - Scraping https://www.deltafaucet.com/bathroom/product/T14459-SS.html with Firecrawl\n",
      "2025-07-05 23:28:44 - StealthScraper - INFO - [stealth_scraper.py:588] - Acquired rate limit for https://www.deltafaucet.com/bathroom/product/T14459-SS.html\n",
      "2025-07-05 23:28:44 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:44 - StealthScraper - INFO - [stealth_scraper.py:276] - Requests failed, trying Firecrawl...\n",
      "2025-07-05 23:28:44 - StealthScraper - INFO - [stealth_scraper.py:586] - Scraping https://www.deltafaucet.com/bathroom/product/55085-SS with Firecrawl\n",
      "2025-07-05 23:28:44 - StealthScraper - INFO - [stealth_scraper.py:588] - Acquired rate limit for https://www.deltafaucet.com/bathroom/product/55085-SS\n",
      "2025-07-05 23:28:44 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:44 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (138149 chars)\n",
      "2025-07-05 23:28:44 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (339567 chars)\n",
      "2025-07-05 23:28:45 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (378850 chars)\n",
      "2025-07-05 23:28:45 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-05 23:28:45 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 3/3 after 2.6s delay\n",
      "2025-07-05 23:28:45 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (337808 chars)\n",
      "2025-07-05 23:28:45 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (323642 chars)\n",
      "2025-07-05 23:28:45 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (315118 chars)\n",
      "2025-07-05 23:28:45 - StealthScraper - INFO - [stealth_scraper.py:276] - Requests failed, trying Firecrawl...\n",
      "2025-07-05 23:28:45 - StealthScraper - INFO - [stealth_scraper.py:586] - Scraping https://www.deltafaucet.com/bathroom/product/75912-SS with Firecrawl\n",
      "2025-07-05 23:28:45 - StealthScraper - INFO - [stealth_scraper.py:588] - Acquired rate limit for https://www.deltafaucet.com/bathroom/product/75912-SS\n",
      "2025-07-05 23:28:45 - StealthScraper - INFO - [stealth_scraper.py:276] - Requests failed, trying Firecrawl...\n",
      "2025-07-05 23:28:45 - StealthScraper - INFO - [stealth_scraper.py:586] - Scraping https://www.deltafaucet.com/bathroom/product/75925-SS with Firecrawl\n",
      "2025-07-05 23:28:45 - StealthScraper - INFO - [stealth_scraper.py:588] - Acquired rate limit for https://www.deltafaucet.com/bathroom/product/75925-SS\n",
      "2025-07-05 23:28:46 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (313559 chars)\n",
      "2025-07-05 23:28:47 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (331327 chars)\n",
      "2025-07-05 23:28:47 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (53791 chars)\n",
      "2025-07-05 23:28:47 - StealthScraper - INFO - [stealth_scraper.py:276] - Requests failed, trying Firecrawl...\n",
      "2025-07-05 23:28:47 - StealthScraper - INFO - [stealth_scraper.py:586] - Scraping https://www.deltafaucet.com/bathroom/product/75950-SS with Firecrawl\n",
      "2025-07-05 23:28:47 - StealthScraper - INFO - [stealth_scraper.py:588] - Acquired rate limit for https://www.deltafaucet.com/bathroom/product/75950-SS\n"
     ]
    }
   ],
   "source": [
    "product_scrape_results = []\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    for id, product_search_result in zip(df['id'], executor.map(stealth_scraper.scrape_url, df['product_url'].to_list())):\n",
    "        product_scrape_results.append({\n",
    "            'id': id,\n",
    "            'product_url': product_search_result.url,\n",
    "            'success': product_search_result.success,\n",
    "            'content_length': len(product_search_result.content) if product_search_result.content else 0,\n",
    "            'status_code': product_search_result.status_code,\n",
    "            'final_method': product_search_result.final_method,\n",
    "            'error_reason': product_search_result.error_reason,\n",
    "            'page_issues': product_search_result.page_issues,\n",
    "            'html_content': product_search_result.content,\n",
    "            'full_result': product_search_result.model_dump_json()\n",
    "        })\n",
    "product_scrape_results_df = pd.DataFrame(product_scrape_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "success  status_code  final_method            \n",
       "True     200          ScrapingMethod.REQUESTS     73\n",
       "False    500          ScrapingMethod.FIRECRAWL    10\n",
       "         404          ScrapingMethod.REQUESTS      4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_scrape_results_df.value_counts(['success', 'status_code', 'final_method'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_scrape_results_df = df.merge(product_scrape_results_df, on='id', how='left') \\\n",
    "    .drop(columns=['product_url_y']) \\\n",
    "    .rename(columns={'product_url_x': 'product_url'})\n",
    "\n",
    "# product_results_df.drop(columns=['html_content', 'full_result']).to_csv(\"01_llmpipeline/1-specbook_scrape_results.csv\", index=False)\n",
    "# product_results_df[['id', 'product_url', 'full_result']].to_csv(\"01_llmpipeline/1-specbook_scrape_content.csv\", index=False)\n",
    "# product_results_df.to_csv(\"01_llmpipeline/1-specbook_scrape.csv\", index=False)\n",
    "# product_results_df = pd.read_csv(\"01_llmpipeline/1-specbook_scrape.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_scrape_results_df_success = product_scrape_results_df[product_scrape_results_df['success'] == True]\n",
    "product_prompts_df = product_scrape_results_df.copy()\n",
    "\n",
    "for id, product_url, html_content in zip(product_scrape_results_df_success['id'], product_scrape_results_df_success['product_url'], product_scrape_results_df_success['html_content']):\n",
    "    cleaned_html = html_processor.clean_html(str(html_content))\n",
    "    cleaned_html_json = cleaned_html.model_dump_json()\n",
    "    prompt = prompt_templator.product_extraction(product_url, cleaned_html_json)\n",
    "    \n",
    "    # Add fields dynamically using loc\n",
    "    product_prompts_df.loc[product_prompts_df['id'] == id, 'cleaned_html'] = cleaned_html_json\n",
    "    product_prompts_df.loc[product_prompts_df['id'] == id, 'cleaned_html_len'] = len(cleaned_html_json)\n",
    "\n",
    "    product_prompts_df.loc[product_prompts_df['id'] == id, 'prompt'] = prompt\n",
    "    product_prompts_df.loc[product_prompts_df['id'] == id, 'prompt_len'] = len(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.to_csv(\"01_llmpipeline/specbook_scrape_results.csv\", index=False)\n",
    "# product_prompts_df = pd.read_csv(\"01_llmpipeline/llm_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_results_df = product_prompts_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-05 23:32:30 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:32:33 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:32:36 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:32:38 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:32:41 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:32:43 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:32:45 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:32:48 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:32:52 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:32:55 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:32:58 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:33:02 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:33:06 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:33:10 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:33:21 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:33:24 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:33:29 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:33:35 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:33:43 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:33:47 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:33:50 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:33:52 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:33:59 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:34:01 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:34:08 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:34:10 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:34:16 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-05 23:34:16 - openai._base_client - INFO - [_base_client.py:1061] - Retrying request to /responses in 0.476560 seconds\n",
      "2025-07-05 23:34:19 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:34:24 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-05 23:34:24 - openai._base_client - INFO - [_base_client.py:1061] - Retrying request to /responses in 0.451469 seconds\n",
      "2025-07-05 23:34:31 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:34:32 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:34:41 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:34:43 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:34:45 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:34:47 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:34:49 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:34:51 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:34:54 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:34:56 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:34:58 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:35:01 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:35:03 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:35:05 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:35:09 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:35:12 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:35:17 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-05 23:35:17 - openai._base_client - INFO - [_base_client.py:1061] - Retrying request to /responses in 0.445367 seconds\n",
      "2025-07-05 23:35:27 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:35:30 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:35:32 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:35:37 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-05 23:35:37 - openai._base_client - INFO - [_base_client.py:1061] - Retrying request to /responses in 0.439362 seconds\n",
      "2025-07-05 23:35:44 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:35:49 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-05 23:35:49 - openai._base_client - INFO - [_base_client.py:1061] - Retrying request to /responses in 0.445812 seconds\n",
      "2025-07-05 23:35:54 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-05 23:35:54 - openai._base_client - INFO - [_base_client.py:1061] - Retrying request to /responses in 0.867715 seconds\n",
      "2025-07-05 23:36:02 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:36:04 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:36:06 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:36:07 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:36:09 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:36:19 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:36:28 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:36:37 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:36:46 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:36:53 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:37:00 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:37:08 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:37:20 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:37:22 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:37:29 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:37:34 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-05 23:37:34 - openai._base_client - INFO - [_base_client.py:1061] - Retrying request to /responses in 0.382708 seconds\n",
      "2025-07-05 23:37:42 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:37:51 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:37:53 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:38:02 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:38:04 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:38:09 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-05 23:38:09 - openai._base_client - INFO - [_base_client.py:1061] - Retrying request to /responses in 0.452692 seconds\n",
      "2025-07-05 23:38:11 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:38:18 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:38:23 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:38:31 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:38:37 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-07-05 23:38:39 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "for id, success, prompt in zip(llm_results_df['id'], llm_results_df['success'], llm_results_df['prompt']):\n",
    "    default_response = PromptTemplator.ProductExtractionOutput(\n",
    "            image_url=\"\",\n",
    "            type=\"\",\n",
    "            description=\"\",\n",
    "            model_no=\"\",\n",
    "            product_link=\"\",\n",
    "            qty=\"\",\n",
    "            key=\"\",\n",
    "        )\n",
    "\n",
    "    if success == True:\n",
    "        llm_response = llm_invocator.invoke_llm(\n",
    "            model_provider=\"openai\",\n",
    "            llm_model_name=\"gpt-4.1\",\n",
    "            prompt=prompt\n",
    "        )\n",
    "        try:\n",
    "            default_response = PromptTemplator.ProductExtractionOutput.model_validate_json(llm_response)\n",
    "        except Exception as e:\n",
    "            print(f\"Error validating response: {e}\")\n",
    "            default_response.description = \"Error validating response\"\n",
    "\n",
    "    llm_results_df.loc[llm_results_df['id'] == id, 'llm_response'] = default_response.model_dump_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_results_df.to_csv(\"01_llmpipeline/llm_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category            87\n",
       "product_url         87\n",
       "id                  87\n",
       "success             87\n",
       "content_length      87\n",
       "status_code         87\n",
       "final_method        87\n",
       "error_reason        14\n",
       "page_issues         87\n",
       "html_content        73\n",
       "full_result         87\n",
       "cleaned_html        73\n",
       "cleaned_html_len    73\n",
       "prompt              73\n",
       "prompt_len          73\n",
       "llm_response        87\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_results_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_result_dicts = [dict(PromptTemplator.ProductExtractionOutput.model_validate_json(response)) for response in llm_results_df['llm_response'].to_list()]\n",
    "product_specs_df = pd.DataFrame(llm_result_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_specs_df.to_csv(\"01_llmpipeline/product_specs.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
