{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T03:49:03.239951Z",
     "start_time": "2025-07-07T03:49:00.573295Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/htttx7197fv90v3w5v6m_s_c0000gn/T/ipykernel_23385/1596269529.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "from tools.html_processor import HTMLProcessor\n",
    "from tools.prompt_templator import PromptTemplator\n",
    "from tools.llm_invocator import LLMInvocator\n",
    "from tools.stealth_scraper import StealthScraper\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "stealth_scraper = StealthScraper()\n",
    "html_processor = HTMLProcessor()\n",
    "prompt_templator = PromptTemplator()\n",
    "llm_invocator = LLMInvocator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"01_llmpipeline/specbook.csv\")\n",
    "df['id'] = range(1, len(df) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 21:14:02 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-06 21:14:02 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (224015 chars)\n",
      "2025-07-06 21:14:02 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (115442 chars)\n",
      "2025-07-06 21:14:02 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (114667 chars)\n",
      "2025-07-06 21:14:02 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (228608 chars)\n",
      "2025-07-06 21:14:02 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (11333 chars)\n",
      "2025-07-06 21:14:02 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (11339 chars)\n",
      "2025-07-06 21:14:02 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (11333 chars)\n",
      "2025-07-06 21:14:02 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-06 21:14:02 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (11357 chars)\n",
      "2025-07-06 21:14:02 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (430751 chars)\n",
      "2025-07-06 21:14:02 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (11339 chars)\n",
      "2025-07-06 21:14:02 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (11437 chars)\n",
      "2025-07-06 21:14:02 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (11477 chars)\n",
      "2025-07-06 21:14:02 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (11375 chars)\n",
      "2025-07-06 21:14:03 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (11399 chars)\n",
      "2025-07-06 21:14:03 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (227835 chars)\n",
      "2025-07-06 21:14:03 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (227835 chars)\n",
      "2025-07-06 21:14:03 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (227835 chars)\n",
      "2025-07-06 21:14:03 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-06 21:14:03 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (610860 chars)\n",
      "2025-07-06 21:14:03 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-06 21:14:03 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (582249 chars)\n",
      "2025-07-06 21:14:03 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (108409 chars)\n",
      "2025-07-06 21:14:03 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (582205 chars)\n",
      "2025-07-06 21:14:03 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 2/3 after 2.5s delay\n",
      "2025-07-06 21:14:03 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 2/3 after 2.4s delay\n",
      "2025-07-06 21:14:03 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (582249 chars)\n",
      "2025-07-06 21:14:03 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-06 21:14:03 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (343002 chars)\n",
      "2025-07-06 21:14:03 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (190304 chars)\n",
      "2025-07-06 21:14:03 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (356516 chars)\n",
      "2025-07-06 21:14:03 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-06 21:14:03 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (341059 chars)\n",
      "2025-07-06 21:14:03 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (502855 chars)\n",
      "2025-07-06 21:14:03 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (146650 chars)\n",
      "2025-07-06 21:14:03 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (145734 chars)\n",
      "2025-07-06 21:14:03 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-06 21:14:04 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (718252 chars)\n",
      "2025-07-06 21:14:04 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-06 21:14:04 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (888250 chars)\n",
      "2025-07-06 21:14:04 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 2/3 after 3.0s delay\n",
      "2025-07-06 21:14:04 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (889952 chars)\n",
      "2025-07-06 21:14:04 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (1016860 chars)\n",
      "2025-07-06 21:14:04 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (922295 chars)\n",
      "2025-07-06 21:14:04 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (909921 chars)\n",
      "2025-07-06 21:14:04 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 2/3 after 2.5s delay\n",
      "2025-07-06 21:14:04 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 2/3 after 1.6s delay\n",
      "2025-07-06 21:14:04 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (685533 chars)\n",
      "2025-07-06 21:14:04 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-06 21:14:04 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 2/3 after 2.0s delay\n",
      "2025-07-06 21:14:04 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (976290 chars)\n",
      "2025-07-06 21:14:04 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-06 21:14:04 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (180581 chars)\n",
      "2025-07-06 21:14:04 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (648367 chars)\n",
      "2025-07-06 21:14:04 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (185486 chars)\n",
      "2025-07-06 21:14:04 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (728405 chars)\n",
      "2025-07-06 21:14:05 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (574700 chars)\n",
      "2025-07-06 21:14:05 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-06 21:14:05 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (158227 chars)\n",
      "2025-07-06 21:14:06 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (129987 chars)\n",
      "2025-07-06 21:14:06 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (535580 chars)\n",
      "2025-07-06 21:14:06 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-06 21:14:06 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 3/3 after 1.5s delay\n",
      "2025-07-06 21:14:06 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (438612 chars)\n",
      "2025-07-06 21:14:06 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-06 21:14:06 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (92049 chars)\n",
      "2025-07-06 21:14:06 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (523496 chars)\n",
      "2025-07-06 21:14:06 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-06 21:14:06 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (475176 chars)\n",
      "2025-07-06 21:14:06 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 3/3 after 2.6s delay\n",
      "2025-07-06 21:14:07 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (429530 chars)\n",
      "2025-07-06 21:14:07 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-06 21:14:07 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 2/3 after 2.6s delay\n",
      "2025-07-06 21:14:07 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-06 21:14:07 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 3/3 after 2.0s delay\n",
      "2025-07-06 21:14:07 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (231817 chars)\n",
      "2025-07-06 21:14:07 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (683227 chars)\n",
      "2025-07-06 21:14:07 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-06 21:14:07 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (692638 chars)\n",
      "2025-07-06 21:14:07 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-06 21:14:07 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (692262 chars)\n",
      "2025-07-06 21:14:07 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 2/3 after 1.3s delay\n",
      "2025-07-06 21:14:07 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 2/3 after 3.0s delay\n",
      "2025-07-06 21:14:07 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (685453 chars)\n",
      "2025-07-06 21:14:07 - StealthScraper - WARNING - [stealth_scraper.py:336] - HTTP 403 error\n",
      "2025-07-06 21:14:07 - StealthScraper - INFO - [stealth_scraper.py:276] - Requests failed, trying Firecrawl...\n",
      "2025-07-06 21:14:07 - StealthScraper - INFO - [stealth_scraper.py:588] - Starting Firecrawl scrape for https://www.potterybarn.com/products/moritz-round-mirror/?catalogId=84&sku=5705623&cm_ven=PLA&cm_cat=Google&cm_pla=Bath%20%3E%20Mirrors&region_id=792000&cm_ite=5705623&gclid=CjwKCAjw1uiEBhBzEiwAO9B_HZ2_K_j4vByLB9LG5R7Wzjl5-7CvVK2uO_EUyZ14R4qGoFl7nelQ-hoCCDcQAvD_BwE\n",
      "2025-07-06 21:14:07 - StealthScraper - INFO - [stealth_scraper.py:590] - Acquired rate limit for https://www.potterybarn.com/products/moritz-round-mirror/?catalogId=84&sku=5705623&cm_ven=PLA&cm_cat=Google&cm_pla=Bath%20%3E%20Mirrors&region_id=792000&cm_ite=5705623&gclid=CjwKCAjw1uiEBhBzEiwAO9B_HZ2_K_j4vByLB9LG5R7Wzjl5-7CvVK2uO_EUyZ14R4qGoFl7nelQ-hoCCDcQAvD_BwE\n",
      "2025-07-06 21:14:07 - StealthScraper - INFO - [stealth_scraper.py:606] - Calling Firecrawl API with timeout=30000ms for https://www.potterybarn.com/products/moritz-round-mirror/?catalogId=84&sku=5705623&cm_ven=PLA&cm_cat=Google&cm_pla=Bath%20%3E%20Mirrors&region_id=792000&cm_ite=5705623&gclid=CjwKCAjw1uiEBhBzEiwAO9B_HZ2_K_j4vByLB9LG5R7Wzjl5-7CvVK2uO_EUyZ14R4qGoFl7nelQ-hoCCDcQAvD_BwE\n",
      "2025-07-06 21:14:08 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (1157391 chars)\n",
      "2025-07-06 21:14:08 - StealthScraper - INFO - [stealth_scraper.py:276] - Requests failed, trying Firecrawl...\n",
      "2025-07-06 21:14:08 - StealthScraper - INFO - [stealth_scraper.py:588] - Starting Firecrawl scrape for https://www.deltafaucet.com/bathroom/product/55085-SS\n",
      "2025-07-06 21:14:08 - StealthScraper - INFO - [stealth_scraper.py:590] - Acquired rate limit for https://www.deltafaucet.com/bathroom/product/55085-SS\n",
      "2025-07-06 21:14:08 - StealthScraper - INFO - [stealth_scraper.py:606] - Calling Firecrawl API with timeout=30000ms for https://www.deltafaucet.com/bathroom/product/55085-SS\n",
      "2025-07-06 21:14:08 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (1404020 chars)\n",
      "2025-07-06 21:14:08 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (1109477 chars)\n",
      "2025-07-06 21:14:08 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (597913 chars)\n",
      "2025-07-06 21:14:08 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (322211 chars)\n",
      "2025-07-06 21:14:09 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (318347 chars)\n",
      "2025-07-06 21:14:09 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 3/3 after 1.5s delay\n",
      "2025-07-06 21:14:09 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (330975 chars)\n",
      "2025-07-06 21:14:09 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-06 21:14:09 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (335299 chars)\n",
      "2025-07-06 21:14:09 - StealthScraper - INFO - [stealth_scraper.py:276] - Requests failed, trying Firecrawl...\n",
      "2025-07-06 21:14:09 - StealthScraper - INFO - [stealth_scraper.py:276] - Requests failed, trying Firecrawl...\n",
      "2025-07-06 21:14:09 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-06 21:14:09 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 3/3 after 1.9s delay\n",
      "2025-07-06 21:14:10 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (317432 chars)\n",
      "2025-07-06 21:14:10 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (332977 chars)\n",
      "2025-07-06 21:14:10 - StealthScraper - INFO - [stealth_scraper.py:276] - Requests failed, trying Firecrawl...\n",
      "2025-07-06 21:14:10 - StealthScraper - INFO - [stealth_scraper.py:302] - Retry 3/3 after 1.2s delay\n",
      "2025-07-06 21:14:10 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (139585 chars)\n",
      "2025-07-06 21:14:11 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (137177 chars)\n",
      "2025-07-06 21:14:11 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-06 21:14:11 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (138150 chars)\n",
      "2025-07-06 21:14:11 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-06 21:14:11 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (315199 chars)\n",
      "2025-07-06 21:14:12 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (339719 chars)\n",
      "2025-07-06 21:14:12 - StealthScraper - INFO - [stealth_scraper.py:276] - Requests failed, trying Firecrawl...\n",
      "2025-07-06 21:14:12 - StealthScraper - INFO - [stealth_scraper.py:276] - Requests failed, trying Firecrawl...\n",
      "2025-07-06 21:14:12 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (337959 chars)\n",
      "2025-07-06 21:14:13 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (323757 chars)\n",
      "2025-07-06 21:14:13 - StealthScraper - INFO - [stealth_scraper.py:309] - Rotated stealth configuration\n",
      "2025-07-06 21:14:13 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (315198 chars)\n",
      "2025-07-06 21:14:13 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (378850 chars)\n",
      "2025-07-06 21:14:13 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (53791 chars)\n",
      "2025-07-06 21:14:14 - StealthScraper - INFO - [stealth_scraper.py:617] - Firecrawl API call completed in 5.95s\n",
      "2025-07-06 21:14:14 - StealthScraper - INFO - [stealth_scraper.py:622] - Firecrawl success for https://www.deltafaucet.com/bathroom/product/55085-SS: 591372 characters scraped\n",
      "2025-07-06 21:14:14 - StealthScraper - INFO - [stealth_scraper.py:588] - Starting Firecrawl scrape for https://www.deltafaucet.com/bathroom/product/T14259-SS\n",
      "2025-07-06 21:14:14 - StealthScraper - INFO - [stealth_scraper.py:590] - Acquired rate limit for https://www.deltafaucet.com/bathroom/product/T14259-SS\n",
      "2025-07-06 21:14:14 - StealthScraper - INFO - [stealth_scraper.py:606] - Calling Firecrawl API with timeout=30000ms for https://www.deltafaucet.com/bathroom/product/T14259-SS\n",
      "2025-07-06 21:14:14 - StealthScraper - INFO - [stealth_scraper.py:390] - Successfully scraped URL with requests (331334 chars)\n",
      "2025-07-06 21:14:17 - StealthScraper - INFO - [stealth_scraper.py:617] - Firecrawl API call completed in 9.65s\n",
      "2025-07-06 21:14:17 - StealthScraper - INFO - [stealth_scraper.py:622] - Firecrawl success for https://www.potterybarn.com/products/moritz-round-mirror/?catalogId=84&sku=5705623&cm_ven=PLA&cm_cat=Google&cm_pla=Bath%20%3E%20Mirrors&region_id=792000&cm_ite=5705623&gclid=CjwKCAjw1uiEBhBzEiwAO9B_HZ2_K_j4vByLB9LG5R7Wzjl5-7CvVK2uO_EUyZ14R4qGoFl7nelQ-hoCCDcQAvD_BwE: 889104 characters scraped\n",
      "2025-07-06 21:14:17 - StealthScraper - INFO - [stealth_scraper.py:588] - Starting Firecrawl scrape for https://www.deltafaucet.com/bathroom/product/559LF-SSLPU\n",
      "2025-07-06 21:14:17 - StealthScraper - INFO - [stealth_scraper.py:590] - Acquired rate limit for https://www.deltafaucet.com/bathroom/product/559LF-SSLPU\n",
      "2025-07-06 21:14:17 - StealthScraper - INFO - [stealth_scraper.py:606] - Calling Firecrawl API with timeout=30000ms for https://www.deltafaucet.com/bathroom/product/559LF-SSLPU\n",
      "2025-07-06 21:14:21 - StealthScraper - INFO - [stealth_scraper.py:617] - Firecrawl API call completed in 11.86s\n",
      "2025-07-06 21:14:21 - StealthScraper - INFO - [stealth_scraper.py:622] - Firecrawl success for https://www.deltafaucet.com/bathroom/product/T14259-SS: 955519 characters scraped\n",
      "2025-07-06 21:14:21 - StealthScraper - INFO - [stealth_scraper.py:588] - Starting Firecrawl scrape for https://www.deltafaucet.com/bathroom/product/75925-SS\n",
      "2025-07-06 21:14:21 - StealthScraper - INFO - [stealth_scraper.py:590] - Acquired rate limit for https://www.deltafaucet.com/bathroom/product/75925-SS\n",
      "2025-07-06 21:14:21 - StealthScraper - INFO - [stealth_scraper.py:606] - Calling Firecrawl API with timeout=30000ms for https://www.deltafaucet.com/bathroom/product/75925-SS\n",
      "2025-07-06 21:14:26 - StealthScraper - INFO - [stealth_scraper.py:617] - Firecrawl API call completed in 16.02s\n",
      "2025-07-06 21:14:26 - StealthScraper - INFO - [stealth_scraper.py:622] - Firecrawl success for https://www.deltafaucet.com/bathroom/product/75925-SS: 398016 characters scraped\n",
      "2025-07-06 21:14:26 - StealthScraper - INFO - [stealth_scraper.py:588] - Starting Firecrawl scrape for https://www.deltafaucet.com/bathroom/product/75912-SS\n",
      "2025-07-06 21:14:26 - StealthScraper - INFO - [stealth_scraper.py:590] - Acquired rate limit for https://www.deltafaucet.com/bathroom/product/75912-SS\n",
      "2025-07-06 21:14:26 - StealthScraper - INFO - [stealth_scraper.py:606] - Calling Firecrawl API with timeout=30000ms for https://www.deltafaucet.com/bathroom/product/75912-SS\n",
      "2025-07-06 21:14:29 - StealthScraper - INFO - [stealth_scraper.py:617] - Firecrawl API call completed in 19.51s\n",
      "2025-07-06 21:14:29 - StealthScraper - INFO - [stealth_scraper.py:622] - Firecrawl success for https://www.deltafaucet.com/bathroom/product/559LF-SSLPU: 796071 characters scraped\n",
      "2025-07-06 21:14:29 - StealthScraper - INFO - [stealth_scraper.py:588] - Starting Firecrawl scrape for https://www.deltafaucet.com/bathroom/product/75950-SS\n",
      "2025-07-06 21:14:29 - StealthScraper - INFO - [stealth_scraper.py:590] - Acquired rate limit for https://www.deltafaucet.com/bathroom/product/75950-SS\n",
      "2025-07-06 21:14:29 - StealthScraper - INFO - [stealth_scraper.py:606] - Calling Firecrawl API with timeout=30000ms for https://www.deltafaucet.com/bathroom/product/75950-SS\n",
      "2025-07-06 21:14:31 - StealthScraper - INFO - [stealth_scraper.py:617] - Firecrawl API call completed in 19.00s\n",
      "2025-07-06 21:14:31 - StealthScraper - INFO - [stealth_scraper.py:622] - Firecrawl success for https://www.deltafaucet.com/bathroom/product/75912-SS: 385657 characters scraped\n",
      "2025-07-06 21:14:37 - StealthScraper - INFO - [stealth_scraper.py:617] - Firecrawl API call completed in 25.02s\n",
      "2025-07-06 21:14:37 - StealthScraper - INFO - [stealth_scraper.py:622] - Firecrawl success for https://www.deltafaucet.com/bathroom/product/75950-SS: 465597 characters scraped\n"
     ]
    }
   ],
   "source": [
    "product_scrape_results = []\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    for id, product_search_result in zip(df['id'], executor.map(stealth_scraper.scrape_url, df['product_url'].to_list())):\n",
    "        product_scrape_results.append({\n",
    "            'id': id,\n",
    "            'product_url': product_search_result.url,\n",
    "            'success': product_search_result.success,\n",
    "            'content_length': len(product_search_result.content) if product_search_result.content else 0,\n",
    "            'status_code': product_search_result.status_code,\n",
    "            'final_method': product_search_result.final_method,\n",
    "            'error_reason': product_search_result.error_reason,\n",
    "            'page_issues': product_search_result.page_issues,\n",
    "            'html_content': product_search_result.content,\n",
    "            'full_result': product_search_result.model_dump_json()\n",
    "        })\n",
    "product_scrape_results_df = pd.DataFrame(product_scrape_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "success  status_code  final_method            \n",
       "True     200          ScrapingMethod.REQUESTS     76\n",
       "                      ScrapingMethod.FIRECRAWL     7\n",
       "False    404          ScrapingMethod.REQUESTS      4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_scrape_results_df.value_counts(['success', 'status_code', 'final_method'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_scrape_results_df = df.merge(product_scrape_results_df, on='id', how='left') \\\n",
    "    .drop(columns=['product_url_y']) \\\n",
    "    .rename(columns={'product_url_x': 'product_url'})\n",
    "\n",
    "# product_results_df.drop(columns=['html_content', 'full_result']).to_csv(\"01_llmpipeline/1-specbook_scrape_results.csv\", index=False)\n",
    "# product_results_df[['id', 'product_url', 'full_result']].to_csv(\"01_llmpipeline/1-specbook_scrape_content.csv\", index=False)\n",
    "# product_results_df.to_csv(\"01_llmpipeline/1-specbook_scrape.csv\", index=False)\n",
    "# product_results_df = pd.read_csv(\"01_llmpipeline/1-specbook_scrape.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_scrape_results_df_success = product_scrape_results_df[product_scrape_results_df['success'] == True]\n",
    "product_prompts_df = product_scrape_results_df.copy()\n",
    "\n",
    "for id, product_url, html_content in zip(product_scrape_results_df_success['id'], product_scrape_results_df_success['product_url'], product_scrape_results_df_success['html_content']):\n",
    "    cleaned_html = html_processor.clean_html(str(html_content))\n",
    "    cleaned_html_json = cleaned_html.model_dump_json()\n",
    "    prompt = prompt_templator.product_extraction(product_url, cleaned_html_json)\n",
    "    \n",
    "    # Add fields dynamically using loc\n",
    "    product_prompts_df.loc[product_prompts_df['id'] == id, 'cleaned_html'] = cleaned_html_json\n",
    "    product_prompts_df.loc[product_prompts_df['id'] == id, 'cleaned_html_len'] = len(cleaned_html_json)\n",
    "\n",
    "    product_prompts_df.loc[product_prompts_df['id'] == id, 'prompt'] = prompt\n",
    "    product_prompts_df.loc[product_prompts_df['id'] == id, 'prompt_len'] = len(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.to_csv(\"01_llmpipeline/specbook_scrape_results.csv\", index=False)\n",
    "# product_prompts_df = pd.read_csv(\"01_llmpipeline/llm_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_results_df = product_prompts_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "998251.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_results_df['prompt_len'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 21:34:22 - httpx - INFO - [_client.py:1025] - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "for id, success, prompt in zip(llm_results_df['id'], llm_results_df['success'], llm_results_df['prompt']):\n",
    "    default_response = PromptTemplator.ProductExtractionOutput(\n",
    "            image_url=\"\",\n",
    "            type=\"\",\n",
    "            description=\"\",\n",
    "            model_no=\"\",\n",
    "            product_link=\"\",\n",
    "            qty=\"\",\n",
    "            key=\"\",\n",
    "        )\n",
    "\n",
    "    if success == True:\n",
    "        try:\n",
    "            llm_response = llm_invocator.invoke_llm(\n",
    "                model_provider=\"openai\",\n",
    "                llm_model_name=\"gpt-4o-mini\",\n",
    "                prompt=prompt\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error invoking LLM: {e}\")\n",
    "            default_response.description = f\"Error invoking LLM: {e}\"\n",
    "\n",
    "        try:\n",
    "            default_response = PromptTemplator.ProductExtractionOutput.model_validate_json(llm_response)\n",
    "        except Exception as e:\n",
    "            print(f\"Error validating response: {e}\")\n",
    "            default_response.description = \"Error validating response\"\n",
    "\n",
    "    llm_results_df.loc[llm_results_df['id'] == id, 'llm_response'] = default_response.model_dump_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category            87\n",
       "product_url         87\n",
       "id                  87\n",
       "success             87\n",
       "content_length      87\n",
       "status_code         87\n",
       "final_method        87\n",
       "error_reason         4\n",
       "page_issues         87\n",
       "html_content        83\n",
       "full_result         87\n",
       "cleaned_html        83\n",
       "cleaned_html_len    83\n",
       "prompt              83\n",
       "prompt_len          83\n",
       "llm_response        40\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_results_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_results_df.to_csv(\"01_llmpipeline/llm_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_prompt_len = llm_results_df['prompt_len'].sum()\n",
    "print(f\"Total prompt length: {total_prompt_len:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_results_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_result_dicts = [dict(PromptTemplator.ProductExtractionOutput.model_validate_json(response)) for response in llm_results_df['llm_response'].to_list()]\n",
    "product_specs_df = pd.DataFrame(llm_result_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_specs_df.to_csv(\"01_llmpipeline/product_specs.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
